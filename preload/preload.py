import argparse
import os
import random
import numpy as np

import pandas as pd

# from utils.Dataloader import generate_multi_view_data
# from .features import load_and_clean_data
parser = argparse.ArgumentParser()
parser.add_argument('--dataset_name', type=str, default='CICIDS', choices=["TONIoT","DoHBrw", "CICIDS", "CICMalMen"],
            help='which dataset to use')
parser.add_argument("--cuda", type=str, default='1', help="Device: cuda:num or cpu.")
parser.add_argument('--texthead', dest='texthead', type=int, default=1000)

args = parser.parse_args()

def load_and_clean_data(file_path, if_shuffle=False):
    df = pd.read_csv(file_path, header=0)
    df.fillna(0, inplace=True)
    if if_shuffle:
        random.seed(42)
        df = df.sample(frac=1, random_state=42).reset_index(drop=True)
    return df

texthead = args.texthead # train_sapmles
dataset_name = args.dataset_name  # CICIDS DoHBrw TONIoT
out_path = f"datasets/{dataset_name}/outputs/"
DATA_PATH = f"../datasets/{dataset_name}/raw/{texthead}.csv"

os.makedirs(os.path.dirname(out_path), exist_ok=True)

# === åŠ è½½å®Œæ•´æ•°æ®é›† ===
df_all = load_and_clean_data(DATA_PATH, if_shuffle=True)
# print(f"âœ… æ€»æ ·æœ¬æ•°: {len(df_all)}")

# === ç”Ÿæˆæè¿°çš„æ ·æœ¬ï¼ˆç§»é™¤ï¼‰ ===
# idx_text = sorted(random.sample(range(len(df_all))))
# df_text = df_all.iloc[idx_text].reset_index(drop=True)
df_all.to_csv(f"{out_path}/text_data.csv", index=False)
# np.save(f"datasets/{out_path}/idx_text.npy", np.array(idx_text))
print(f"å·²é€‰å– {len(df_all)} æ¡ä½œä¸ºæè¿°ç”Ÿæˆæ•°æ®")


# # === ä»åŸå§‹æ•°æ®ä¸­å‰”é™¤å·²ç”¨äºç”Ÿæˆæ–‡æœ¬çš„æ•°æ®ï¼Œå†å¾—åˆ°æµ‹è¯•é›† ===
# df_train = df_all.drop(index=idx_text).reset_index(drop=True)
# df_train.to_csv(f"datasets/{out_path}/test_data.csv", index=False)
# print(f"ğŸ“‚ å‰©ä½™è®­ç»ƒæ•°æ®ä¿å­˜è‡³: datasets/{out_path}/test_data.csv")

# np.save(f"datasets/{out_path}/test_data.npy", df_train.values)
# print(f"ğŸ“¦ å‰©ä½™è®­ç»ƒæ•°æ®ä¹Ÿä¿å­˜ä¸º NPY æ ¼å¼: datasets/{out_path}/test_data.npy")
